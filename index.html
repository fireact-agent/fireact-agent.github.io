<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>FireAct: Toward Language Agent Fine-tuning</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://kit.fontawesome.com/deb78776bf.js" crossorigin="anonymous"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">FireAct: Toward Language Agent Fine-tuning</h1>
            <br>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=IFKToXUAAAAJ&hl=en" target="_blank">Baian Chen</a><sup>1*</sup>,</span>
                <span class="author-block">
                  <a href="https://ciaranshu.github.io" target="_blank">Chang Shu</a><sup>2*</sup>,</span>
                  <span class="author-block">
                    <a href="https://eehsan.github.io" target="_blank">Ehsan Shareghi</a><sup>3</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="https://sites.google.com/site/nhcollier/" target="_blank">Nigel Collier</a><sup>2</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="https://www.cs.princeton.edu/~karthikn/" target="_blank">Karthik Narasimhan</a><sup>4</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="https://ysymyth.github.io" target="_blank">Shunyu Yao</a><sup>4</sup>,</span>
                  </span>

                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Language and Technology Lab<sup>2</sup>, Princeton Language and Intelligence<sup>4</sup> <br>System2 Research<sup>1</sup>, University of Cambridge<sup>2</sup>, Monash University<sup>3</sup>, Princeton University<sup>4</sup></span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary Model link -->
                    <span class="link-block">
                      <a href="https://huggingface.co/forestai/fireact_llama_2_7b" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fa-regular fa-box-archive"></i>
                      </span>
                      <span>Model</span>
                    </a>
                  </span>

                    <!-- Supplementary data link -->
                    <span class="link-block">
                      <a href="https://github.com/anchen1011/FireAct/tree/main/data" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fa fa-database"></i>
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/anchen1011/FireAct" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="item has-text-centered">
      <img src="static/images/teaser.pdf" alt="Teaser image" class="teaser-image" width="90%">
      </div>
      <h2 class="subtitle has-text-centered">
        While language agents and language model fine-tuning are both popular topics, their intersection is understudied. This work takes an initial step to show multiple advantages of fine-tuning LMs for agentic uses, and opens up various new questions toward language agent fine-tuning.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent efforts have expanded the capabilities of language models (LMs) by integrating them with external tools or environments, resulting in the development of language agents capable of reasoning and taking actions. However, the majority of these agents heavily rely on few-shot prompting techniques.

          In this paper, we advocate for a less explored approach: the fine-tuning of LMs to create language agents. We present an initial series of systematic investigations in this direction. Using a question-answering (QA) setup with a Google search API, we examine a range of factors, including the selection of base LMs, agent methodologies, fine-tuning datasets, and QA tasks. Our research consistently demonstrates that language agents experience performance enhancements after fine-tuning their core LMs.

          For instance, fine-tuning with 500 GPT-4 generated agent trajectories results in a remarkable 77% improvement in the performance of a Llama2-7B agent on the HotpotQA task. Additionally, we introduce a novel approach, labeled as "method," which involves fine-tuning LMs with agent trajectories originating from multiple tasks and agent methodologies, enabling the agent to be more flexible.

          In summary, our findings emphasize the often-overlooked advantages of fine-tuned language agents compared to their prompting-based counterparts. We offer empirical guidelines for the fine-tuning process and indicate promising directions for the development of improved tasks and methodologies for language agents.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method -->
<section class="section" id="method">
  <div class="container is-max-desktop content">
    <h2 class="title">Method</h2>
    <div class="item has-text-centered">
      <img src="static/images/method.pdf" alt="Teaser image" class="teaser-image" width="90%">
      </div>
    <p>
       The FireAct framework includes two steps: <br>
       (a) <strong>During the fine-tuning</strong>, a robust language model (e.g., GPT-4) generates task-solving paths by analyzing questions from various datasets and employing diverse methods as prompts. These effective paths are then translated into the ReAct format to fine-tune a smaller language model (e.g. Llama2-7B).
       <br>
       (b) <strong>During inference</strong>, the fine-tuned language model can operate without the need for explicit prompts and has the capability to autonomously select an agent method, allowing it to complete ReAct trajectories with adaptable lengths, thus accommodating varying levels of question complexity. The example "3+4+5=" represents an ad-hoc question for illustration purposes.
    </p>
    </div>
  </div>
</section>


<!--Result-->
<section class="section" id="">
  <div class="container is-max-desktop content">
    <h2 class="title">Results</h2>
      <!DOCTYPE html>
<html>
<head>
  <style>
    table {
      border-collapse: collapse;
      width: 100%;
    }

    th, td {
      border: 1px solid #dddddd;
      text-align: left;
      padding: 8px;
    }

    th {
      background-color: #f2f2f2;
    }
  </style>
</head>
<body>

<table>
  <tr>
    <td>
      <table>
        <caption>Few-shot Prompting results.</caption>
        <tr>
          <th></th>
          <th>Prompt</th>
          <th>EM</th>
        </tr>
        <tr>
          <td rowspan="3">GPT-4</td>
          <td>IO</td>
          <td>37.2</td>
        </tr>
        <tr>
          <td>CoT</td>
          <td><b>45.0</b></td>
        </tr>
        <tr>
          <td>ReAct</td>
          <td>42.0</td>
        </tr>
        <tr>
          <td rowspan="3">GPT-3.5</td>
          <td>IO</td>
          <td>22.4</td>
        </tr>
        <tr>
          <td>CoT</td>
          <td>28.0</td>
        </tr>
        <tr>
          <td>ReAct</td>
          <td><b>31.4</b></td>
        </tr>
      </table>
    </td>
    <td>
      <table>
        <caption>Prompting vs. fine-tuning, with absolute/relative increases.</caption>
        <tr>
          <th></th>
          <th>ReAct</th>
          <th>FireAct</th>
          <th>abs./rel. diff</th>
        </tr>
        <tr>
          <td>Llama-2-7B</td>
          <td>14.8</td>
          <td>26.2</td>
          <td>+11.4 / <b>77%</b></td>
        </tr>
        <tr>
          <td>Llama-2-13B</td>
          <td><b>21.2</b></td>
          <td>34.4</td>
          <td><b>+13.1</b> / 62%</td>
        </tr>
        <tr>
          <td>CodeLlama-7B</td>
          <td>17.4</td>
          <td>27.8</td>
          <td>+10.4 / 60%</td>
        </tr>
        <tr>
          <td>CodeLlama-13B</td>
          <td>20.8</td>
          <td>29.0</td>
          <td>+8.2 / 39%</td>
        </tr>
        <tr>
          <td>CodeLlama-34B</td>
          <td><b>22.2</b></td>
          <td>27.8</td>
          <td>+5.6 / 25%</td>
        </tr>
        <tr>
          <td>GPT-3.5</td>
          <td><b>31.4</b></td>
          <td><b>39.2</b></td>
          <td>+7.8 / 25%</td>
        </tr>
      </table>
    </td>
  </tr>
</table>

<p><strong>Fine-tuning significantly improves agent performance.</strong> Fine-tuning consistently and substantially enhances HotpotQA EM scores compared to prompting alone. We observe that even weaker language models benefit significantly from fine-tuning, with Llama-2-7B showing a remarkable 77% increase. Stronger models like GPT-3.5 also see a 25% improvement, highlighting the advantages of fine-tuning across various scenarios. When comparing fine-tuned Llama-2-13B to strong prompting baselines, it outperforms all GPT-3.5 prompting methods (IO/CoT/ReAct). This suggests that fine-tuning smaller, open-source language models can outperform prompting with larger, commercial counterparts. Notably, even the strongest fine-tuned LM, GPT-3.5, outperforms GPT-4 + IO prompting but falls behind GPT-4 + CoT/ReAct prompting, indicating room for further improvement.</p>

<table>
  <caption>Comparison of costs, robustness, and generalization for fine-tuned vs. prompted GPT-3.5.</caption>
  <tr>
    <th></th>
    <th colspan="2">Cost per trial</th>
    <th colspan="3">Obs. Robustness (EM)</th>
    <th>Generalization</th>
  </tr>
  <tr>
    <th></th>
    <th>Money ($)</th>
    <th>Time (s)</th>
    <th>Normal</th>
    <th>None</th>
    <th>Random</th>
    <th>Bamboogle (EM)</th>
  </tr>
  <tr>
    <td>FireAct</td>
    <td><strong>2.2 × 10<sup>-3</sup></strong></td>
    <td><strong>2.7</strong></td>
    <td><strong>39.2</strong></td>
    <td><strong>33.6</strong></td>
    <td><strong>37.2</strong></td>
    <td><strong>44.0</strong></td>
  </tr>
  <tr>
    <td>ReAct</td>
    <td>2.6 × 10<sup>-3</sup></td>
    <td>9.0</td>
    <td>31.4</td>
    <td>20.8</td>
    <td>22.6</td>
    <td>40.8</td>
  </tr>
</table>


<p><strong>Fine-tuning also offers cost and time advantages during agent inference.</strong> Since fine-tuned LMs do not require few-shot in-context examples, their inference becomes more efficient, especially in agentic applications with iterative context accumulation. For instance, the cost comparison between fine-tuned and prompted GPT-3.5 inference shows a substantial reduction in inference time by 70% (9.0s to 2.7s per trial) and a decrease in inference cost, despite the higher expense associated with fine-tuned inference. While these costs may vary under different conditions (e.g., parallelism implementation), the benefits of having a much smaller context are evident.</p>
<p><strong>Robustness to noisy tools.</strong> The tools or environments that language agents interact with are not always trustworthy, which has led to safety concerns like jailbreaking or prompt injection. Here we consider a simplified and harmless setup, where the search API has a probability of 0.5 to return 1) "None" or 2) a random search response (from all previous experiments and trials), and ask if language agents could still robustly answer questions. As shown in the second part of Table 3, the "None" setup turns out to be the more challenging one, which lowered <strong>ReAct</strong> EM by 33.8% and <strong>FireAct</strong> EM only by 14.2%. Interestingly, random observations hurt <strong>ReAct</strong> by a similar degree (28.0% drop), but do not hurt <strong>FireAct</strong> much (only a 5.1% drop), possibly because the fine-tuning trajectories already contain examples of noisy search queries and how GPT-4 "reacts" to such noises successfully. These initial results hint at the importance of a more diverse learning support for robustness.</p>
<p><strong>Generalization to new tasks.</strong> The third part of the table shows EM results of fine-tuned and prompted GPT-3.5 on a test set of multi-hop questions that cannot be directly answered by searching on Google. While both fine-tuned and prompted GPT-3.5 show reasonable generalization to these questions, fine-tuning outperforms prompting, suggesting its generalization advantages. Similarly, combining few-shot prompts with fine-tuning greatly improves performance on these questions. However, fine-tuning on one QA dataset does not generalize well to other datasets with different question styles and answer formats, motivating further experiments in multi-task fine-tuning.</p>


</div>
</section>



<!-- Example -->
<section class="section" id="example">
  <div class="container is-max-desktop content">
    <h2 class="title">Analysis</h2>
    <!-- insert two figures data_scale and data_type side by side-->
    <div class="columns is-centered">
      <div style="width: 30%;">
        <div class="item has-text-centered">
          <img src="static/images/data_scale.pdf" alt="Teaser image" class="teaser-image" width="90%">
        </div>
      </div>
      <div style="width: 70%;">
        <div class="item has-text-centered">
          <img src="static/images/data_type.pdf" alt="Teaser image" class="teaser-image" width="90%">
        </div>
      </div>
  </div>
  <p><strong>Effect of fine-tuning data scale.</strong> This analysis explores how <strong>FireAct</strong> performances scale with the number of fine-tuning trajectories (<em>n</em> in {100, 200, 500, 1000}). GPT-3.5 appears very sample-efficient, requiring only 100 samples to reach an EM around 35, and the gain after 200 samples is marginal. On the other hand, Llama models cannot even learn the <strong>ReAct</strong> format using 100 or 200 samples, but non-trivial EMs "emerge" with 500 samples, and most models (except CodeLlama-13B) further improve with 1,000 samples.
   
      <div class="item has-text-centered">
        <img src="static/images/traj.pdf" alt="Teaser image" class="teaser-image" width="90%">
        </div>
        <p><strong>Multi-method fine-tuning increases agent flexibility.</strong> Before presenting quantitative results, we offer two example questions to illustrate the benefit of multi-method <strong>FireAct</strong> fine-tuning. The first question (a) is simple, but the <strong>ReAct</strong>-only fine-tuned agent (a1) searched for an over-complicated query, leading to distraction and a wrong answer. In contrast, an agent fine-tuned with both CoT and <strong>ReAct</strong> chose to solve the task within one round, relying on confident internal knowledge. The second question (b) is more challenging, and the <strong>ReAct</strong>-only fine-tuned agent (b1) kept searching queries ending in "during the Libyan Civil War" without useful information. In contrast, an agent fine-tuned with both Reflexion and <strong>ReAct</strong> reflected upon this problem and pivoted the search strategy to change the time constraint to "during his rule," which led to the right answer. The flexibility to implicitly choose methods for different problems is another key advantage of fine-tuning over prompting.</p>
        <p><strong>Multi-method fine-tuning affects different LMs differently.</strong> Despite the intuitive benefit, mixing more methods does not always improve results, and the optimal mix of methods depends on the base LM. For example, <strong>ReAct+CoT</strong> outperforms <strong>ReAct</strong> for GPT-3.5 and Llama-2 models, but hurts for CodeLlama models. <strong>ReAct+CoT+Reflexion</strong> is the worst for CodeLlama-7/13B, but is the best for CodeLlama-34B. These non-trivial results call for further studies of the interaction of base LMs and fine-tuning data.</p> 
      </div>
    </div> 
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->




  <footer class="footer">
    <!-- add three logo to the footer -->
    <div class="container is-max-desktop content">
    <div style="display: flex; justify-content: space-between;">
      <div style="width: 20%;">
        <a href="https://ltl.mmll.cam.ac.uk" target="_blank">
          <img src="static/images/ltl_logo.png" alt="University of Cambridge" width="100%">
        </a>
      </div>
      <div style="width: 30%; margin-left: 20px; margin-right: 20px;">
        <a href="https://www.monash.edu/" target="_blank">
          <img src="static/images/monash-logo.png" alt="Monash University" width="100%">
        </a>
      </div>
      <div style="width: 40%;">
        <a href="https://pli.princeton.edu" target="_blank">
          <img src="static/images/princeton-logo.svg" alt="Princeton University" width="100%">
        </a>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
